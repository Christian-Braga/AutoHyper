{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AutoHyper**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoHyper is designed to facilitate hyperparameter optimization (HPO) for supervised learning models on tabular data.\n",
    "It serves as a lightweight, modular, and fully customizable package, giving you fine-grained control over the entire tuning and validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How To Use AutoHyper**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the aim of this notebook is to make an unbiased comparison between two basic hyper parameter optimization technique:\n",
    "In order to explain and undestand the main differences and strenghts.\n",
    "\n",
    "- grid search\n",
    "\n",
    "- random search \n",
    "\n",
    "Breve spiegazione delle due tecniche (con pro/contro teorici).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from src.autohyper import HPO\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TESTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing Dataset and convert it into a pandas DataFrame\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    X,\n",
    "    columns=[\n",
    "        \"MedInc\",\n",
    "        \"HouseAge\",\n",
    "        \"AveRooms\",\n",
    "        \"AveBedrms\",\n",
    "        \"Population\",\n",
    "        \"AveOccup\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "    ],\n",
    ")\n",
    "y = pd.Series(y, name=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "data_features = X\n",
    "data_target = y\n",
    "hp_values = {\n",
    "    \"max_depth\": [1, 3, 5, 9, 12, 15, 20, 35, 40, 60, 100],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2, 0.5, 0.7, 0.9],\n",
    "    \"n_estimators\": [10, 30, 50, 60, 70, 80, 90, 100],\n",
    "}\n",
    "task = \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-14 23:07:55] [\u001b[32mINFO\u001b[0m] Initialized HPO class\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_hpo = HPO(\n",
    "    model=model,\n",
    "    data_features=data_features,\n",
    "    data_target=data_target,\n",
    "    hp_values=hp_values,\n",
    "    task=task,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **01. GRID SEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-14 23:07:58] [\u001b[32mINFO\u001b[0m] ################################################ HPO ################################################\u001b[0m\n",
      "[2025-06-14 23:07:58] [\u001b[32mINFO\u001b[0m] Starting Nested Cross-Validation for HPO\u001b[0m\n",
      "[2025-06-14 23:07:58] [\u001b[32mINFO\u001b[0m] ================================================================================================\u001b[0m\n",
      "[2025-06-14 23:07:58] [\u001b[32mINFO\u001b[0m] Number of outer folds: 5, Number of inner folds: 3, Method: grid_search\u001b[0m\n",
      "[2025-06-14 23:07:58] [\u001b[32mINFO\u001b[0m] Target task: regression\u001b[0m\n",
      "[2025-06-14 23:07:58] [\u001b[32mINFO\u001b[0m] ================================================================================================\u001b[0m\n",
      "[2025-06-14 23:07:58] [\u001b[32mINFO\u001b[0m] OUTER FOLD 1/5 STARTED\u001b[0m\n",
      "[2025-06-14 23:07:58] [\u001b[32mINFO\u001b[0m] Starting Grid Search...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/christianbraga/Desktop/github/AutoHyper/Tests/01_basic_HPO.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/christianbraga/Desktop/github/AutoHyper/Tests/01_basic_HPO.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m grid_search \u001b[39m=\u001b[39m test_hpo\u001b[39m.\u001b[39;49mhp_tuning(hpo_method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgrid_search\u001b[39;49m\u001b[39m\"\u001b[39;49m, outer_k\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, inner_k\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/github/AutoHyper/src/autohyper/hpo.py:311\u001b[0m, in \u001b[0;36mHPO.hp_tuning\u001b[0;34m(self, hpo_method, outer_k, inner_k, n_trials, parents_selection_mechanism, parents_selection_ratio, max_generations, n_new_configs, shuffle)\u001b[0m\n\u001b[1;32m    309\u001b[0m hpo_technique \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_search\n\u001b[1;32m    310\u001b[0m \u001b[39m# Call the HPO method and obtain the best configuration in the inner_cv loop\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m best_config_inner_cv \u001b[39m=\u001b[39m hpo_technique(\n\u001b[1;32m    312\u001b[0m     X\u001b[39m=\u001b[39;49mX_outer_train,\n\u001b[1;32m    313\u001b[0m     y\u001b[39m=\u001b[39;49my_outer_train,\n\u001b[1;32m    314\u001b[0m     n_splits\u001b[39m=\u001b[39;49minner_k,\n\u001b[1;32m    315\u001b[0m )\n\u001b[1;32m    316\u001b[0m \u001b[39m# Remove 'fitness' key if present\u001b[39;00m\n\u001b[1;32m    317\u001b[0m best_config_inner_cv\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfitness\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/github/AutoHyper/src/autohyper/hpo.py:160\u001b[0m, in \u001b[0;36mHPO.grid_search\u001b[0;34m(self, X, y, n_splits)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mfor\u001b[39;00m i, configuration \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(hyperparameters_configs, \u001b[39m1\u001b[39m):\n\u001b[1;32m    156\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    157\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEvaluating config \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(hyperparameters_configs)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mconfiguration\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n\u001b[0;32m--> 160\u001b[0m     avg_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inner_cross_validation(configuration, X, y, n_splits)\n\u001b[1;32m    161\u001b[0m     store_metrics\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39mconfiguration\u001b[39m\u001b[39m\"\u001b[39m: configuration, \u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m: avg_score})\n\u001b[1;32m    163\u001b[0m \u001b[39m# Find the best configuration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/github/AutoHyper/src/autohyper/hpo.py:124\u001b[0m, in \u001b[0;36mHPO._inner_cross_validation\u001b[0;34m(self, configuration, X, y, n_splits)\u001b[0m\n\u001b[1;32m    121\u001b[0m X_train, X_val \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[train_idx], X\u001b[39m.\u001b[39miloc[test_idx]\n\u001b[1;32m    122\u001b[0m y_train, y_val \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_idx], y\u001b[39m.\u001b[39miloc[test_idx]\n\u001b[0;32m--> 124\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m    125\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[1;32m    126\u001b[0m metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_metrics(y_true\u001b[39m=\u001b[39my_val, y_pred\u001b[39m=\u001b[39my_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/autohyper-env/lib/python3.11/site-packages/xgboost/core.py:705\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    704\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 705\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/autohyper-env/lib/python3.11/site-packages/xgboost/sklearn.py:1247\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1248\u001b[0m     params,\n\u001b[1;32m   1249\u001b[0m     train_dmatrix,\n\u001b[1;32m   1250\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1251\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1252\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1253\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1254\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1255\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1256\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1257\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1258\u001b[0m     callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[1;32m   1259\u001b[0m )\n\u001b[1;32m   1261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/autohyper-env/lib/python3.11/site-packages/xgboost/core.py:705\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    704\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 705\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/autohyper-env/lib/python3.11/site-packages/xgboost/training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    182\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, iteration\u001b[39m=\u001b[39;49mi, fobj\u001b[39m=\u001b[39;49mobj)\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    185\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/autohyper-env/lib/python3.11/site-packages/xgboost/core.py:2223\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2219\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2221\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2222\u001b[0m     _check_call(\n\u001b[0;32m-> 2223\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\n\u001b[1;32m   2224\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mc_int(iteration), dtrain\u001b[39m.\u001b[39;49mhandle\n\u001b[1;32m   2225\u001b[0m         )\n\u001b[1;32m   2226\u001b[0m     )\n\u001b[1;32m   2227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2228\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search = test_hpo.hp_tuning(hpo_method=\"grid_search\", outer_k=5, inner_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **02. Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = test_hpo.hp_tuning(\n",
    "    hpo_method=\"random_search\", outer_k=5, inner_k=3, n_trials=35\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **03. Evolutionary Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolutionary_algo = test_hpo.hp_tuning(\n",
    "    hpo_method=\"evolutionary_algorithm\",\n",
    "    outer_k=5,\n",
    "    inner_k=3,\n",
    "    parents_selection_mechanism=\"fitness_proportional_selection\",\n",
    "    parents_selection_ratio=0.5,\n",
    "    n_new_configs=10,\n",
    "    max_generations=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
