{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AutoHyper**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoHyper is designed to facilitate hyperparameter optimization (HPO) for supervised learning models on tabular data.\n",
    "It serves as a lightweight, modular, and fully customizable package, giving you fine-grained control over the entire tuning and validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoHyper is designed to:\n",
    "\n",
    "- Provide a clear and consistent interface for different HPO strategies: at the moment grid search, random search, and evolutionary algorithms.\n",
    "\n",
    "- Leverage nested cross-validation to deliver robust and unbiased estimates of out-of-sample model performance.\n",
    "\n",
    "- Incorporate a custom selection mechanism that combines performance and robustness using a weighted scoring function, ensuring the best configurations are both accurate and consistently effective across multiple resampling iterations.\n",
    "\n",
    "- Return structured outputs, ideal for quantitative comparison and visual inspection of configurations.\n",
    "\n",
    "- Offer detailed logging and configuration ranking based on a composite score of performance and frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Components of Hyperparameter Optimization in AutoHyper**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical hyperparameter optimization (HPO) problem consists of **five essential components** . AutoHyper is designed to give users full control and flexibility over each of these:\n",
    "\n",
    "1. **`Learner`**\n",
    "\n",
    "The learner is the machine learning model to be tuned. In AutoHyper, any supervised model following the **scikit-learn API** is supported. This includes both classifiers and regressors such as RandomForestClassifier, XGBRegressor, LogisticRegression, and even custom models wrapped using **SciKeras** (for Keras) or **Skorch** (for PyTorch). The only requirement is that the model must implement `fit(X, y)`, `predict(X)`, and `set_params(**kwargs)`.\n",
    "\n",
    "2. **`Hyperparameter Space`**\n",
    "\n",
    "The search space defines the set of hyperparameters to explore. AutoHyper allows users to specify this space as a dictionary of parameter names and candidate values. The search space is dynamically parsed based on the selected optimization strategy. When needed particularly in random search or evolutionary algorithms, AutoHyper can **automatically infer and apply the most appropriate value scale** for each hyperparameter, such as linear sampling for float and integer parameters, and categorical sampling for discrete options. This enables more efficient exploration, especially when dealing with large or non-uniform hyperparameter domains.\n",
    "\n",
    "3. **`Dataset`**\n",
    "\n",
    "AutoHyper is specifically tailored for **tabular datasets**, where `X` is a `pandas.DataFrame` and `y` is a `pandas.Series` or `numpy.ndarray`. The dataset is passed directly to the HPO class and internally split according to the specified resampling strategy. The package assumes clean, preprocessed data, leaving feature engineering and preprocessing under the user's control for maximal transparency and modularity.\n",
    "\n",
    "4. **`Resampling Strategy`** \n",
    "\n",
    "\n",
    "To avoid overfitting and ensure unbiased evaluation, AutoHyper leverages **nested cross-validation**. The outer loop estimates generalization performance, while the inner loop performs hyperparameter tuning. Users can configure the number of outer and inner folds (`n_outer_folds`, `n_inner_folds`), making the resampling strategy fully customizable. This separation guarantees a rigorous assessment of how the chosen hyperparameters would perform on truly unseen data.\n",
    "\n",
    "5. **`Performance Measure`**\n",
    "\n",
    "Evaluation is handled using common metrics like accuracy, f1, precision, recall for classification and r2, neg_mean_squared_error, etc., for regression. The user specifies the metric via the scoring parameter. Internally, AutoHyper calculates average performance for each configuration across all outer folds and applies a **custom weighted scoring function** that balances average performance with robustness (measured as frequency of selection), ensuring the final recommendation is both strong and stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optimization Strategies - How To Use AutoHyper**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from src.autohyper import HPO\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TESTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing Dataset and convert it into a pandas DataFrame\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    X,\n",
    "    columns=[\n",
    "        \"MedInc\",\n",
    "        \"HouseAge\",\n",
    "        \"AveRooms\",\n",
    "        \"AveBedrms\",\n",
    "        \"Population\",\n",
    "        \"AveOccup\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "    ],\n",
    ")\n",
    "y = pd.Series(y, name=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "data_features = X\n",
    "data_target = y\n",
    "hp_values = {\n",
    "    \"max_depth\": [1, 3, 9, 12, 20],\n",
    "    \"learning_rate\": [0.1, 0.2, 0.5, 0.9],\n",
    "    \"n_estimators\": [10, 30, 50, 70],\n",
    "}\n",
    "task = \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hpo = HPO(\n",
    "    model=model,\n",
    "    data_features=data_features,\n",
    "    data_target=data_target,\n",
    "    hp_values=hp_values,\n",
    "    task=task,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **01. GRID SEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = test_hpo.hp_tuning(hpo_method=\"grid_search\", outer_k=5, inner_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **02. Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = test_hpo.hp_tuning(\n",
    "    hpo_method=\"random_search\", outer_k=5, inner_k=3, n_trials=35\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **03. Evolutionary Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolutionary_algo = test_hpo.hp_tuning(\n",
    "    hpo_method=\"evolutionary_algorithm\",\n",
    "    outer_k=5,\n",
    "    inner_k=3,\n",
    "    parents_selection_mechanism=\"tournament_selection\",\n",
    "    parents_selection_ratio=0.5,\n",
    "    n_new_configs=10,\n",
    "    max_generations=20,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
