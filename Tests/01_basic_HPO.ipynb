{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic HPO - Grid Search and Random Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the aim of this notebook is to make an unbiased comparison between two basic hyper parameter optimization technique:\n",
    "In order to explain and undestand the main differences and strenghts.\n",
    "\n",
    "- grid search\n",
    "\n",
    "- random search \n",
    "\n",
    "Breve spiegazione delle due tecniche (con pro/contro teorici).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **01. Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **0. Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from src import HPO\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing Dataset and convert it into a pandas DataFrame\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    X,\n",
    "    columns=[\n",
    "        \"MedInc\",\n",
    "        \"HouseAge\",\n",
    "        \"AveRooms\",\n",
    "        \"AveBedrms\",\n",
    "        \"Population\",\n",
    "        \"AveOccup\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\n",
    "    ],\n",
    ")\n",
    "y = pd.Series(y, name=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "data_features = X\n",
    "data_target = y\n",
    "hp_values = {\n",
    "    \"max_depth\": [1, 3, 5],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"n_estimators\": [10, 30, 50],\n",
    "}\n",
    "task = \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hpo = HPO(\n",
    "    model=model,\n",
    "    data_features=data_features,\n",
    "    data_target=data_target,\n",
    "    hp_values=hp_values,\n",
    "    task=task,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **01. GRID SEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = test_hpo.hp_tuning(hpo_method=\"grid_search\", outer_k=5, inner_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **02. Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hpo.hp_tuning(hpo_method=\"random_search\", outer_k=5, inner_k=3, n_trials=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"max_depth\": [1, 3, 5], \"learning_rate\": [0.01, 0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combinations = list(\n",
    "    itertools.product(param_grid[\"max_depth\"], param_grid[\"learning_rate\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for combination in param_combinations:\n",
    "#     model = xgb.XGBRegressor(*combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = HPO(model, data_features=features, data_target=target, hp_values=param_grid)\n",
    "\n",
    "print(test.grid_search())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape of the metrics saved in the outer loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each element of the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"fold\": fold_idx,\n",
    "    \"metrics\": {\"r2\": 0.82, \"mse\": 0.15, \"rmse\": 0.387, \"mae\": 0.3},\n",
    "    \"best_config\": {\"max_depth\": 5, \"learning_rate\": 0.1, \"n_estimators\": 200},\n",
    "    \"hpo_time_seconds\": 120.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_metrics = [\n",
    "    {\"configuration\": {\"a\": 1, \"b\": 2}, \"results\": 1},\n",
    "    {\"configuration\": {\"a\": 10, \"b\": 20}, \"results\": 5},\n",
    "]\n",
    "\n",
    "best_configuration = store_metrics[0][\"configuration\"]\n",
    "best_config_results = store_metrics[0][\"results\"]\n",
    "for config_metrics in store_metrics:\n",
    "    if config_metrics[\"results\"] > best_config_results:\n",
    "        best_configuration = config_metrics[\"configuration\"]\n",
    "        best_config_results = config_metrics[\"results\"]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "best_configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[X] i changed the output structure of the tuning parameter i need to understand it more clearly, in successive phase i can reason more on the output structure to simplify it and enache visualization\n",
    "\n",
    "[X] create the random search method\n",
    "\n",
    "[X] sistema output hpo_tuning \n",
    "\n",
    "[X]create the logger mechanism to show the steps of the classifier / model so to have a nice visualization of the model behaviour (figo come in progetto avatar il fatto di mostrare una tabella markdown nel logger con i risultati invece di printare e quindi imparare il meccanismo dei logger fatti bene) \n",
    "in modo da non dare sempre il dizionario per il lato backend ma dare il dizionario solo se viene fatto print\n",
    "\n",
    "[ ] logger implementato correttaemente, sistema da un punto di vista visuale la struttura dei logs\n",
    "\n",
    "[ ]create the data visualization method\n",
    "\n",
    "[ ]create the EA method\n",
    "\n",
    "[ ]creazione primo noteboook per mostrare funzionamento del pacchetto su grid search e random search\n",
    "\n",
    "[ ] create the bayesian optmization method\n",
    "\n",
    "[ ] creazione secondo noteboook per mostrare funzionamento del pacchetto su EA in dettaglio\n",
    "\n",
    "[ ] pubblicazione pacchetto con spiegazione generale\n",
    "\n",
    "[ ] pubblicazione primo notebook di test random e grid search \n",
    "\n",
    "[ ] pubblicazione secondo notebook funzionamento EA \n",
    "\n",
    "[ ] creazione terzo notebook per mostrare funzionamento del pacchetto su Bayesian Opt\n",
    "\n",
    "[ ] pubblicazione terzo notebook Bayesian Opt\n",
    "\n",
    "[ ] creare metodo per hyperparameter importance, quindi implementare logiche per selezionare, valutare l'importanza dei singoli hyperparameter\n",
    "\n",
    "[ ] creare notebook per mostrare le strategie di HP importance\n",
    "\n",
    "[ ] pubblicare notebook hyperparameter importance\n",
    "\n",
    "[ ] creare automl pipeline method\n",
    "\n",
    "[ ] creare notebook per presentare automl pipeline\n",
    "\n",
    "FINE \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
